
https://github.com/plkdthfss/StormComputingDemo

## 所需软件版本
	虚拟机VMware Workstation Pro17
	系统 centos7
	ftp xftp8
	storm2.4.0
	zookeeper3.5.7
	kafka3.5.7
	redis6.2.14
	jdk1.8.0_212-b10
	maven 3.6.2
	gcc 4.8.5

## 实际操作
### 制作模版虚拟机，打通本机与虚拟机通讯
1.先ping一下，如果成功的话就是网络没问题
```
ping www.baidu.com
```
2.关闭防火墙（通常开发的时候，整体对外是有严密的防火墙防护的，但是内部单个服务器为了通信方便一般是开放防火墙的）
```
systemctl stop firewalld
systemctl disable firewalld.service
```
3.打通本机与虚拟机通讯设置
	1
```
sudo vim /etc/sysconfig/network-scripts/ifcfg-ens33

# 将文件修改为下面这个，有的修改，有的
DEVICE=ens33
TYPE=Etherne
ONBOOT=yes
BOOTPROTO=static
NAME="ens33"
IPADDR=192.168.10.102  # 前面192.168.10为子网IP，后面的102可以自己定
PREFIX=24
GATEWAY=192.168.10.2   # 下图网关
DNS1=192.168.10.2      # DNS服务器地址
```
	2查看Linux虚拟机的虚拟网络编辑器，编辑->虚拟网络编辑器->VMnet8
	
![[Pasted image 20251024211951.png]]
	3查看Windows系统适配器VMware Network Adapter VMnet8的IP地址
		保证Linux系统ifcfg-ens33文件中IP地址、虚拟网络编辑器地址和Windows系统VM8网络IP地址相同。
	4配置Linux克隆机主机名称映射hosts文件
		打开/etc/hosts
```
		vim /etc/hosts
		
		# 添加下面的内容
		192.168.10.100 hadoop100
		192.168.10.101 hadoop101
		192.168.10.102 hadoop102   #以此类推，之后reboot重启
```

	5修改windows的主机映射文件（hosts文件） c盘的windows/system32/drivers/hosts
```
		192.168.10.100 hadoop100
		192.168.10.101 hadoop101
		192.168.10.102 hadoop102  #同样以此类推
```
	6在Powershell验证是否能双向通信，如果数据包能传过去就说明成功了
```
	ping hadoop102
```
	7其余：复制机子之后修改各自的ip，然后改自己的主机名 /etc/hostname


### Java配置
与下面zookeeper差不多

### Zookeeper安装与配置
1下载地址：https://zookeeper.apache.org/
2下载他的安装包到本地，然后用ftp工具传到linux下面，解压（推荐大家创建两个目录，一个目录放安装包，一个目录放解压后的文件，我的是module和software）
```
# 进入你的压缩包的目录，-C后面是你要解析文件到哪个目录下
tar -zxvf apache-zookeeper-3.5.7-bin.tar.gz -C /opt/module/  

# 修改名字
mv apache-zookeeper-3.5.7 zookeeper-3.5.7env
```
3修改配置文件
	1将/opt/module/zookeeper-3.5.7/conf 这个路径下的 zoo_sample.cfg 修改为 zoo.cfg；
	
```
mv zoo_sample.cfg zoo.cfg
```

	2打开 zoo.cfg 文件，修改 dataDir 路径：
```
	vim zoo.cfg
	
	# 修改
	dataDir=/opt/module/zookeeper-3.5.7/zkData
	
	# 添加
	#######################cluster##########################

server.5=hadoop105:2888:3888

server.6=hadoop106:2888:3888

server.7=hadoop107:2888:3888
	
	#退出来之后创建zkData文件夹
	
	# zkData创建myid文件
```

4配置环境变量
	1在/etc/profile.d/my_env.sh添加目录，然后退出来生效：
```
# 记得换成你自己的目录
#ZOOKEEPER_HOME
export ZOOKEEPER_HOME=/opt/module/zookeeper-3.5.7
export PATH=$PATH:$ZOOKEEPER_HOME/bin


# 退出来生效
source /etc/profile
```

	2分发文件，配置启动脚本，在用户目录的bin文件夹下创建myzk文件，复制脚本，然后给予权限，注意脚本里面的主机名称和文件路径要换成自己的
```
#!/bin/bash

case $1 in

    "start"){

    for i in hadoop102 hadoop103 hadoop104

    do

        echo ---------- zookeeper $i 启动 ------------

        ssh $i "/opt/module/zookeeper-3.5.7/bin/zkServer.sh start"

    done

    };;

  

    "stop"){

    for i in hadoop102 hadoop103 hadoop104

    do

        echo ---------- zookeeper $i 停止 ------------

        ssh $i "/opt/module/zookeeper-3.5.7/bin/zkServer.sh stop"

    done

    };;

  

    "status"){

    for i in hadoop102 hadoop103 hadoop104

    do

        echo ---------- zookeeper $i 状态 ------------

        ssh $i "/opt/module/zookeeper-3.5.7/bin/zkServer.sh status"

    done

    };;

esac

```

```
	chmod 775 myzk
```

5启动zookeeper
```
myzk start
```
### Strom安装与配置
下载：[https://storm.apache.org/downloads.html](https://storm.apache.org/downloads.html)
1下载，解压，改名，与zookeeper一致
2进入Storm解压后的文件夹下的conf目录，vim打开sstorm.yaml
3修改为下面这样，同样注意里面的主机名与路径得改成自己的（同时注意Storm的默认端口是8080，但是spark的默认端口也是8080，所以如果你在打开spark的情况下再打开Storm就会端口冲突，导致UI出不来，而且我们下一步的SpringBoot的默认端口也是8080，所以这里改为8085）：
```
storm.zookeeper.servers:
  - "hadoop105"
  - "hadoop106"
  - "hadoop107"

nimbus.seeds: ["hadoop105"]
storm.local.dir: "/opt/module/storm/data"
storm.workers.artifacts.dir: "/opt/module/storm/logs/workers-artifacts"
supervisor.slots.ports:
  - 6700
  - 6701
  - 6702
ui.port: 8085
```
4创建/opt/module/storm-2.4.0/data这里的data和logs目录
5分发文件，配置启动脚本，给权限，与zookeeper一致，同样注意修改主机名与路径
```
#!/bin/bash

  

ZOOKEEPER_NODES=(hadoop102 hadoop103 hadoop104)

SUPERVISOR_NODES=(hadoop103 hadoop104)

STORM_HOME=/opt/module/storm-2.4.0

ZOOKEEPER_HOME=/opt/module/zookeeper-3.5.7

  

case $1 in

    "start"){

        echo "########## 启动 ZooKeeper 集群  ##########"

  

        for host in "${ZOOKEEPER_NODES[@]}"; do

            echo "--- 启动 ZooKeeper on $host ---"

            ssh $host "$ZOOKEEPER_HOME/bin/zkServer.sh start"

        done

  

        echo "########## 启动 Storm 主节点服务 (Nimbus / UI / Logviewer) ##########"

  

        ssh hadoop102 "nohup $STORM_HOME/bin/storm nimbus >/dev/null 2>&1 &"

        ssh hadoop102 "nohup $STORM_HOME/bin/storm ui >/dev/null 2>&1 &"

        ssh hadoop102 "nohup $STORM_HOME/bin/storm logviewer >/dev/null 2>&1 &"

  

        echo "########## 启动 Storm 从节点服务 (Supervisor / Logviewer) ##########"

        for host in "${SUPERVISOR_NODES[@]}"; do

        echo "--- 启动 Supervisor on $host ---"

            ssh $host "nohup $STORM_HOME/bin/storm supervisor >/dev/null 2>&1 &"

            ssh $host "nohup $STORM_HOME/bin/storm logviewer >/dev/null 2>&1 &"

        done

  

        echo "########## 检查进程状态 ##########"

        for host in "${ZOOKEEPER_NODES[@]}"; do

            echo "--- $host ---"

            ssh $host "jps | grep -E 'QuorumPeerMain|Nimbus|Supervisor|UI|Logviewer'"

        done

  

        echo "Storm 集群已启动完成！"

        echo "Web UI: http://hadoop102:8085"

        echo "============================================"

    };;

  

esac
```

6打开storm
```
	mystorm start
```
### redis安装与配置：
https://blog.csdn.net/qq_39135287/article/details/83474865?ops_request_misc=elastic_search_misc&request_id=64032832d99a60a680e12b569dc66876&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-83474865-null-null.142^v102^pc_search_result_base3&utm_term=linux%E9%85%8D%E7%BD%AEredis&spm=1018.2226.3001.4187

下载redis
```
cd /opt/software
wget http://download.redis.io/releases/redis-6.2.14.tar.gz
tar -zxvf redis-6.2.14.tar.gz -C /opt/module
```

安装c语言环境：
```
yum install gcc-c++
```
进入redis文件夹编译：
```
//进入到/opt/module/redis-6.2.14/ 文件目录下
[root@hadoop102 mnt]# cd /opt/module/redis-6.2.14/   
 
[root@hadoop102 redis-5.0.0]# make      //对解压后的文件进行编译
 
[root@hadoop102 redis-5.0.0]# cd ./src   //进入到 redis-6.2.14/src 文件目录下
 
[root@hadoop102 src]# make install    //进行redis安装
```

确认是否安装好了
```
[yjy@hadoop102 src]$ redis-server -v
Redis server v=6.2.14 sha=00000000:0 malloc=jemalloc-5.1.0 bits=64 build=59b5bf78b82ded75
```

为了方便管理，建立etc和bin来统一管理文件
把redis.conf放到etc，把src里面的mkreleasehdr.sh、redis-benchmark、redis-check-aof、redis-cli、redis-server放到bin文件夹
```
mv redis.conf ./etc/
cd src
mv mkreleasehdr.sh redis-benchmark redis-check-aof redis-cli redis-server /opt/modle/redis-6.2.14/bin/
```

进入etc文件夹修改redis.conf文件
```
cd ../etc
vim redis.conf
```

```
# 修改下面的项目
# 把bind注释掉，让外部可访问
# bind 127.0.0.1

# 允许后台运行
daemonize yes

# 关闭保护模式（允许远程连接）
protected-mode no

# 数据文件目录
dir /opt/module/redis/data
```

启动redis
```
# 进入bin文件夹
cd /opt/module/redis-6.2.14/bin
./redis-server ../redis.conf
```

验证是否启动成功

```
ps -ef | grep redis
```
![[Pasted image 20251021222521.png]]

redis客户端测试
```
cd /opt/module/redis-6.2.14/bin
./redis-cli
```

测试windows是否可以访问6379端口
```
 Test-NetConnection -ComputerName hadoop102 -Port 6379
```
![[Pasted image 20251021221631.png]]

或者写一段Python代码
```
# 需要安装redis库

import redis

r = redis.Redis(host='192.168.10.102', port=6379)

r.set('test', 'redis ok')

print(r.get('test'))
```

![[Pasted image 20251021222824.png]]

### Kafka安装与配置：
下载kafka：https://archive.apache.org/dist/kafka/3.7.2/kafka_2.13-3.7.2.tgz

```
cd /opt/softwares
tar -zxvf kafka_2.12-3.7.0.tgz -C /opt/module
mv kafka_2.12-3.7.0 kafka
```
```
sudo vim /etc/profile.d/my_env.sh

# 添加下面的信息
export KAFKA_HOME=/opt/module/kafka
export PATH=$PATH:$KAFKA_HOME/bin

source /etc/profile

```

```
# 修改配置文件
cd /opt/module/kafka/config
vim server.properties

# 每个 broker 唯一 ID(其他两个机子改为2/3)
broker.id=1

# Kafka 存储日志的路径（多个目录可逗号分隔）
log.dirs=/opt/module/kafka/data

# Zookeeper 连接地址（Kafka 3.x 可改为 KRaft）
zookeeper.connect=hadoop105:2181,hadoop106:2181,hadoop107:2181

# 监听端口
listeners=PLAINTEXT://0.0.0.0:9092

# 外部访问地址（重点：让 Windows 能访问！）（其他两个改为各自的）
advertised.listeners=PLAINTEXT://hadoop105:9092
```

```
vim zookeeper.properties

# dataDir 改为这个
dataDir=/opt/module/kafka/zkdata
```

```
#!/bin/bash

# 启动脚本

for i in hadoop102 hadoop103 hadoop104

do

   case $1 in

      "start")

        echo "-------------start $i -------------"

        ssh $i "/opt/module/kafka/bin/kafka-server-start.sh -daemon /opt/module/kafka/config/server.properties"

  ;;        

      "stop")

        echo "-------------stop $i -------------"

        ssh $i "/opt/module/kafka/bin/kafka-server-stop.sh stop"

  ;;

  esac        

done

```

测试是否成功
```
jpsall
可以看到kafka
```

![[Pasted image 20251021212020.png]]

测试windows本地访问是否成功（前提windows的hosts要有Hadoop102的映射）：
打开Powershell
```
 Test-NetConnection -ComputerName hadoop102 -Port 9092
```

![[Pasted image 20251021221703.png]]






### maven的安装与配置（windows物理机）
https://blog.csdn.net/m0_72528211/article/details/136403342?ops_request_misc=%257B%2522request%255Fid%2522%253A%252261580ed615190e7488423cc83ceb9b16%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=61580ed615190e7488423cc83ceb9b16&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-136403342-null-null.142^v102^pc_search_result_base7&utm_term=idea%E9%85%8D%E7%BD%AEmaven&spm=1018.2226.3001.4187

### 流程

打开hadoop，zookeeper，storm，kafka，redis
创建idea项目，导入代码，重启maven
本地运行：
	运行KafkaToRedisTopology
	运行PaymentInfoProducter
	运行SpringBootServiceApplication
	打开浏览器的http://localhost:8080/index.html

```
在卡夫卡目录下查看是否写入
bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic sales_events --from-beginning
```

```
查看是否写入redis
redis-cli -h 192.168.10.102
LRANGE sales:timeline 0 -1
```

```
# 1)所有产品的“当前销量”
HGETALL sales:realtime:count

# 2)Top 10 销量最高的产品（member=productId, score=销量）
ZREVRANGE sales:leaderboard:count 0 9 WITHSCORES

# 3) 单个产品的销量曲线
LRANGE sales:timeline:count:PRODUCTID5 -20 -1
# 输出格式： "timestamp,totalCount"

```

## 理论流程
### Redis
### Kafka

### 代码结构
```
src/main/java/com/yjy/
│
├── createorder/                
│   └── PaymentInfoProducer.java
│
├── topology/                    
│   ├── spout/
│   │   └── KafkaSpoutConfigUtil.java
│   ├── bolt/
│   │   ├── ProcessBolt.java
│   │   ├── AggregateBolt.java
│   │   └── RedisBolt.java
│   └── KafkaToRedisTopology.java  

```


```
```plaintext
src/
├── main/
│   ├── java/
│   │   └── com/
│   │       └── yjy/
│   │           ├── createorder/                 # 生产者模块（已有）
│   │           │   └── PaymentInfoProducer.java  # Kafka消息生产者
│   │           │
│   │           ├── topology/                    # 拓扑处理模块
│   │           │   ├── spout/
│   │           │   │   └── KafkaSpoutConfigUtil.java  # Kafka Spout配置工具
│   │           │   ├── bolt/
│   │           │   │   ├── ProcessBolt.java       # 数据解析处理Bolt
│   │           │   │   ├── AggregateBolt.java     # 数据聚合计算Bolt
│   │           │   │   └── RedisBolt.java         # Redis存储Bolt
│   │           │   └── KafkaToRedisTopology.java  # 拓扑主类（协调Spout和Bolt）
│   │           │
│   │           └── util/                         # 工具类模块
│   │               └── RedisClient.java           # Redis连接池工具类
│   │
│   └── resources/                               # 配置资源目录
│       ├── redis.properties                      # Redis连接配置（host、port等）
│       ├── kafka.properties                      # Kafka配置（broker地址、topic等）
│       └── log4j.properties                      # 日志配置（可选）
│
└── test/                                         # 测试目录（可选）
    └── java/
        └── com/
            └── yjy/
                ├── createorder/
                └── topology/
```


### 流程图
```



           ┌──────────────────────────────────────────┐
           │                  用户界面                 │
           │    实时监控面板                            │
           │   - 实时柱状图：各商品销    售量/金额对比     │
           │   - 折线图：单品趋势 / 总体趋势              │
           │   - 数字卡片：总销售额 / 总销售量            │
           └───────────────▲──────────────────────────┘
                           │ REST API
                           │ JSON 格式返回实时数据
           ┌───────────────┴──────────────────────────┐
           │            Spring Boot 后端服务           │
           │  - 使用 Jedis 连接 Redis                 │
           │  - 定义接口：                   │
           │     /api/realtime/count                  │
           │     /api/realtime/amount                 │
           │     /api/total                           │
           │     /api/timeline/{productId}            │
           │  - 定期轮询 Redis，返回最新数据           │
           └───────────────▲──────────────────────────┘
                           │ Redis 查询
           ┌───────────────┴──────────────────────────┐
           │                 Redis 缓存层              │
           │  - sales:realtime（Hash） 金额             │
           │  - sales:realtime:count（Hash） 数量        │
           │  - sales:timeline（List） 总金额趋势        │
           │  - sales:timeline:count:{productId}（List） │
           │  - sales:leaderboard:count（ZSet） 排行榜   │
           └───────────────▲──────────────────────────┘
                           │ Storm 实时流
           ┌───────────────┴──────────────────────────┐
           │                 Storm 流处理层             │
           │  - KafkaSpout：实时消费订单流              │
           │  - ProcessBolt：解析订单                   │
           │  - AggregateBolt：计算金额与数量累计        │
           │  - RedisBolt：写入 Redis                   │
           └───────────────▲──────────────────────────┘
                           │
                           │ Kafka 订单流
           ┌───────────────┴──────────────────────────┐
           │             Kafka + Producer              │
           │   Producer 定期发送 PaymentInfo            │
           │   (orderId, productId, productPrice...)   │
           └──────────────────────────────────────────┘


```


随机生成的数据会存入kafka的sales_events：
```
{
  "orderId": "a2cf6343285848989516a4cc617d38f5",
  "productId": "PRODUCTID5",
  "productPrice": 125,
  "timestamp": 1761106903296
}
```

接下来是Storm实时处理，先从kafka那里把数据拉来
kafkaSpout --> ProcessBolt --> AggregateAolt --> RedisBolt

读取kafka数据 --> 解析Json --> 聚合计算 --> 将结果存入Redis

#### kafkaSpout
kafka存储的是字节数组（二进制数据），kafkaSpout就是从kafka拉取字节消息，转成字符串，然后封装成Storm的Tuple对象，发射给下游的Bolt

```
{
  "fields": ["value"],
  "values": ["{\"orderId\":\"a2cf...\",\"productId\":\"PRODUCTID5\",\"productPrice\":125,\"timestamp\":1761106903296}"]
}

```
#### ProcessBolt
结束后kafkaSpout传来的数据，然后把解析json，拿出里面的数值字段
```
{
  "fields": ["productId", "productPrice", "timestamp"],
  "values": ["PRODUCTID5", 125.0, 1761106903296]
}

```
#### AggregateBolt
两个Map分别管理数量和金额

```
{
  "fields"：["productId", "productTotal", "totalSales", "productCount", "totalCount", "timestamp"],
  "values"：["PRODUCT001", 299.99, 299.99, 1, 1, 1730000000000]
}
```
#### RedisBolt
把上面的数据存入Redis

```
sales:realtime            (Hash)
sales:total               (String)
sales:timeline            (List)
```


SpringBoot后端
调用顺序：
Controller → Repository → JedisPool → Redis
## 问题

1.刚开始有时候总金额会有一个往回跳的情况，时高时低：

这不是 Redis 的问题，也不是 RedisBolt 的逻辑问题。  
核心问题在于：

> ⚙️ **AggregateBolt 维护了全局状态，但在 Storm 分布式执行时，每个 Task 有自己独立的内存副本。**

也就是说：

- Storm 默认会启动多个 `AggregateBolt` 实例（Task）。
    
- 每个 Task 维护自己的 `productSales`、`productCount`、`totalSales`、`totalCount`。
    
- 这些 Task 并不知道对方的状态（不共享内存）。
    
- 如果你的拓扑中有 **多个并行度**（parallelism > 1），不同 Task 会处理不同的 productId 流；
    
- 但 RedisBolt 最终聚合所有 Task 输出 → 数据时间上会“乱序”，  
    这导致 “某 Task 的总额（较小）在另一个 Task 的更大值之后写入 Redis”。
    

于是你看到总额出现“回退”，本质上是多实例间竞争写入的结果。

	1.将并行度设置为1，直接解决分布式的竞争带来的问题
	2.在写入Redis的时候做一个筛选，只有比前一个大的才能写入法（但也有可能出错）
	3.直接取消AggregateBolt这种存储，换成Bolt直接写入redis，后续的聚合从redis里面读然后算

2.第一版代码断开重连数据会翻倍的涨，排查之后发现是应为kafka队列内消息的保存时间太长，导致代码每一次给断开重连都会重读kafka里全部的数据，造成数据的偏差。
	最简单的解决办法就是把kafka里面消息保存时间换为1s，这样每次断开重启测试的时候就不会有这种问题，但是这样的话如果是真实开发中发生故障下线或者消费者端由于各种原因延迟大于1s的话，系统就会丢失数据，一般根据真实情况改这个时间（主要咋们这个有频繁的断开重连操作，如果一直开着不会有什么问题）
```
	# 进入 Kafka 安装目录的 bin 目录（根据实际路径调整） 
	cd /opt/module/kafka/bin 
	# 修改主题的消息保留时间（1000ms，就是1s） 
	./kafka-configs.sh --bootstrap-server     hadoop105:9092,hadoop106:9092,hadoop107:9092 \ 
	--alter --topic sales_events \ 
	--add-config retention.ms=1000
```

